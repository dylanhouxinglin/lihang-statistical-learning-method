{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "import math\n",
    "from math import log\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 5.1 from book\n",
    "def create_data():\n",
    "    datasets = [['青年', '否', '否', '一般', '否'],\n",
    "               ['青年', '否', '否', '好', '否'],\n",
    "               ['青年', '是', '否', '好', '是'],\n",
    "               ['青年', '是', '是', '一般', '是'],\n",
    "               ['青年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '好', '否'],\n",
    "               ['中年', '是', '是', '好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '好', '是'],\n",
    "               ['老年', '是', '否', '好', '是'],\n",
    "               ['老年', '是', '否', '非常好', '是'],\n",
    "               ['老年', '否', '否', '一般', '否'],\n",
    "               ]\n",
    "    labels = [u'年龄', u'有工作', u'有自己的房子', u'信贷情况', u'类别']\n",
    "    \n",
    "    return datasets, labels\n",
    "\n",
    "datasets, labels = create_data()\n",
    "train_data = pd.DataFrame(datasets, columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, root=True, label=None, feature_name=None, feature=None):\n",
    "        self.root = root\n",
    "        self.label = label\n",
    "        self.feature_name = feature_name\n",
    "        self.feature = feature\n",
    "        self.tree = {}\n",
    "        self.result = {'label' : self.label, 'feature' : self.feature, 'tree' : self.tree}\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '{}'.format(self.result)\n",
    "    \n",
    "    def add_node(self, val, node):\n",
    "        self.tree[val] = node\n",
    "        \n",
    "    def predict(self, features):\n",
    "        if self.root is True:\n",
    "            return self.label\n",
    "        return self.tree[features[self.feature]].predict(features)\n",
    "\n",
    "class DTree:\n",
    "    def __init__(self, epsilon=0.1):\n",
    "        self.epsilon = epsilon\n",
    "        self._tree = {}\n",
    "        \n",
    "    def cal_entropy(datasets):\n",
    "        n = len(datasets)\n",
    "        label_count = {}\n",
    "        # get distribution(Pi)\n",
    "        for i in range(n):\n",
    "            label = datasets[i][-1]\n",
    "            if label not in label_count:\n",
    "                label_count[label] = 0\n",
    "            label_count[label] += 1\n",
    "        # print(label_count) {'否': 6, '是': 9}\n",
    "        empirical_entropy = -sum([(p/n) * log(p/n, 2) for p in label_count.values()])\n",
    "\n",
    "        return empirical_entropy\n",
    "\n",
    "    # empirical conditional entropy\n",
    "    def cal_conditional_entropy(self, datasets, axis=0):\n",
    "        n = len(datasets)\n",
    "        feature_sets = {}\n",
    "        for i in range(n):\n",
    "            feature = datasets[i][axis]\n",
    "            if feature not in feature_sets:\n",
    "                feature_sets[feature] = []\n",
    "            feature_sets[feature].append(datasets[i])\n",
    "\n",
    "        empirical_conditional_entropy = sum([(len(p)/n) * cal_entropy(p)\n",
    "                                            for p in feature_sets.values()])\n",
    "\n",
    "        return empirical_conditional_entropy\n",
    "\n",
    "    # information gain\n",
    "    def info_gain(entropy, con_entropy):\n",
    "        return entropy - con_entropy\n",
    "\n",
    "    def get_info_gain(self, datasets):\n",
    "        feature_count = len(datasets[0]) - 1\n",
    "        empirical_entropy = cal_entropy(datasets)\n",
    "        best_feature = []\n",
    "\n",
    "        for c in range(feature_count):\n",
    "            c_info_gain = info_gain(empirical_entropy, cal_conditional_entropy(datasets, axis=c))\n",
    "            best_feature.append((c, c_info_gain))\n",
    "\n",
    "        best = max(best_feature, key=lambda x : x[-1])\n",
    "        # best : ((feature_id, feature_info_gain))\n",
    "        return best\n",
    "    \n",
    "    def train(self, train_data):\n",
    "        '''\n",
    "        Input : Dataset(DataFrame), Feature_set A, threshold eta\n",
    "        Output : T\n",
    "        '''\n",
    "        _ = train_data.iloc[:, :-1]\n",
    "        y_train = train_data.iloc[:, -1]\n",
    "        features = train_data.columns[:-1]\n",
    "\n",
    "        \n",
    "        # 1. if all the data in D all belong to the same class C, \n",
    "        #    set T as a root node and use C as the label, return T\n",
    "        if len(y_train.value_counts()) == 1:\n",
    "            return Node(root = True, label = y_train.iloc[0])\n",
    "        \n",
    "        # 2. if feature A is empty, set T as root node and use the most C as the label, \n",
    "        #    return T\n",
    "        if len(features) == 0:\n",
    "            return Node(root = True, \n",
    "                        label = y_train.value_counts().sort_values(ascending=False).index[0])\n",
    "        \n",
    "        # 3. calculate the largest inforamtion gain, use Ag to representative the best feature\n",
    "        max_feature_id, max_info_gain = self.get_info_gain(np.array(train_data))\n",
    "        max_feature_name = features[max_feature_id]\n",
    "        \n",
    "        # 4. if the information gain is smaller than threshold, set T as root node, and use\n",
    "        #    the most C as the label, return T\n",
    "        if max_info_gain < self.epsilon:\n",
    "            return Node(root = True, \n",
    "                       label = y_train.value_counts().sort_values(ascending=False).index[0])\n",
    "\n",
    "        # 5. splitting D according to every possible values in feature A\n",
    "        node_tree = Node(root = False, feature_name = max_feature_name, \n",
    "                         feature = max_feature_id)\n",
    "        \n",
    "        feature_list = train_data[max_feature_name].value_counts().index\n",
    "        for f in feature_list:\n",
    "            sub_train_df = train_data.loc[train_data[max_feature_name] == f].drop([\n",
    "                                                        max_feature_name], axis=1)\n",
    "            \n",
    "            # 6. create tree recursively\n",
    "            sub_tree = self.train(sub_train_df)\n",
    "            node_tree.add_node(f, sub_tree)\n",
    "        \n",
    "        pprint.pprint(node_tree.tree)\n",
    "    \n",
    "        return node_tree \n",
    "    \n",
    "    def fit(self, train_data):\n",
    "        self._tree = self.train(train_data)\n",
    "        \n",
    "        return self._tree\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        return self._tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'否': {'label': '否', 'tree': {}, 'feature': None},\n",
      " '是': {'label': '是', 'tree': {}, 'feature': None}}\n",
      "{'否': {'label': None, 'tree': {'是': {'label': '是', 'tree': {}, 'feature': None}, '否': {'label': '否', 'tree': {}, 'feature': None}}, 'feature': 1},\n",
      " '是': {'label': '是', 'tree': {}, 'feature': None}}\n"
     ]
    }
   ],
   "source": [
    "datasets, labels = create_data()\n",
    "data_df = pd.DataFrame(datasets, columns = labels)\n",
    "dt = DTree()\n",
    "tree = dt.fit(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': None, 'tree': {'是': {'label': '是', 'tree': {}, 'feature': None}, '否': {'label': None, 'tree': {'是': {'label': '是', 'tree': {}, 'feature': None}, '否': {'label': '否', 'tree': {}, 'feature': None}}, 'feature': 1}}, 'feature': 2}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'否'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.predict(['老年', '否', '否', '一般'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
