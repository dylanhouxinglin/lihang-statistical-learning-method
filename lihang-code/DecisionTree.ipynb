{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "import math\n",
    "from math import log\n",
    "\n",
    "import sys\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 5.1 from book\n",
    "def create_data():\n",
    "    datasets = [['teen', 'no', 'no', 'intermediate', 'no'],\n",
    "               ['teen', 'no', 'no', 'good', 'no'],\n",
    "               ['teen', 'yes', 'no', 'good', 'yes'],\n",
    "               ['teen', 'yes', 'yes', 'intermediate', 'yes'],\n",
    "               ['teen', 'no', 'no', 'intermediate', 'no'],\n",
    "               ['middle-age', 'no', 'no', 'intermediate', 'no'],\n",
    "               ['middle-age', 'no', 'no', 'good', 'no'],\n",
    "               ['middle-age', 'yes', 'yes', 'good', 'yes'],\n",
    "               ['middle-age', 'no', 'yes', 'very-good', 'yes'],\n",
    "               ['middle-age', 'no', 'yes', 'very-good', 'yes'],\n",
    "               ['old', 'no', 'yes', 'very-good', 'yes'],\n",
    "               ['old', 'no', 'yes', 'good', 'yes'],\n",
    "               ['old', 'yes', 'no', 'good', 'yes'],\n",
    "               ['old', 'yes', 'no', 'very-good', 'yes'],\n",
    "               ['old', 'no', 'no', 'intermediate', 'no'],\n",
    "               ]\n",
    "    labels = ['age', 'have job', 'own house', 'credit situation', 'type']\n",
    "    \n",
    "    return datasets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, root=True, label=None, feature_name=None, feature=None):\n",
    "        self.root = root\n",
    "        self.label = label\n",
    "        self.feature_name = feature_name\n",
    "        self.feature = feature\n",
    "        self.tree = {}\n",
    "        self.result = {'label' : self.label, 'feature' : self.feature, 'tree' : self.tree}\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '{}'.format(self.result)\n",
    "    \n",
    "    def add_node(self, val, node):\n",
    "        self.tree[val] = node\n",
    "        \n",
    "    def predict(self, test_features):\n",
    "        if self.root is True:\n",
    "            return self.label\n",
    "        # self.feature : 2, 1\n",
    "        # test_features : 'own house', 'have job'\n",
    "        return self.tree[test_features[self.feature]].predict(test_features)\n",
    "\n",
    "class DTree:\n",
    "    def __init__(self, epsilon=0.1):\n",
    "        self.epsilon = epsilon\n",
    "        self._tree = {}\n",
    "        \n",
    "    def cal_entropy(self, datasets):\n",
    "        n = len(datasets)\n",
    "        label_count = {}\n",
    "        # get distribution(Pi)\n",
    "        for i in range(n):\n",
    "            label = datasets[i][-1]\n",
    "            if label not in label_count:\n",
    "                label_count[label] = 0\n",
    "            label_count[label] += 1\n",
    "        # print(label_count) {'no': 6, 'yes': 9}\n",
    "        empirical_entropy = -sum([(p/n) * log(p/n, 2) for p in label_count.values()])\n",
    "\n",
    "        return empirical_entropy\n",
    "\n",
    "    # empirical conditional entropy\n",
    "    def cal_conditional_entropy(self, datasets, axis=0):\n",
    "        n = len(datasets)\n",
    "        feature_sets = {}\n",
    "        for i in range(n):\n",
    "            feature = datasets[i][axis]\n",
    "            if feature not in feature_sets:\n",
    "                feature_sets[feature] = []\n",
    "            feature_sets[feature].append(datasets[i])\n",
    "\n",
    "        empirical_conditional_entropy = sum([(len(p)/n) * self.cal_entropy(p)\n",
    "                                            for p in feature_sets.values()])\n",
    "\n",
    "        return empirical_conditional_entropy\n",
    "\n",
    "    # information gain\n",
    "    def info_gain(self, entropy, con_entropy):\n",
    "        return entropy - con_entropy\n",
    "\n",
    "    def get_info_gain(self, datasets):\n",
    "        feature_count = len(datasets[0]) - 1\n",
    "        empirical_entropy = self.cal_entropy(datasets)\n",
    "        best_feature = []\n",
    "\n",
    "        for c in range(feature_count):\n",
    "            c_info_gain = self.info_gain(empirical_entropy, \n",
    "                                         self.cal_conditional_entropy(datasets, axis=c))\n",
    "            best_feature.append((c, c_info_gain))\n",
    "\n",
    "        best = max(best_feature, key=lambda x : x[-1])\n",
    "        # best : ((feature_id, feature_info_gain))\n",
    "        return best\n",
    "    \n",
    "    def train(self, train_data):\n",
    "        '''\n",
    "        Input : Dataset(DataFrame), Feature_set A, threshold epsilon\n",
    "        Output : T(Decision Tree)\n",
    "        '''\n",
    "        _ = train_data.iloc[:, :-1]\n",
    "        y_train = train_data.iloc[:, -1]\n",
    "        features = train_data.columns[:-1]\n",
    "\n",
    "        \n",
    "        # 1. if all the data in D belong to the same class C, \n",
    "        #    set T as single node and use C as the label, return T\n",
    "        if len(y_train.value_counts()) == 1:\n",
    "            return Node(root = True, label = y_train.iloc[0])\n",
    "        \n",
    "        # 2. if feature A is empty, set T as single node and use the most C as the label, \n",
    "        #    return T\n",
    "        if len(features) == 0:\n",
    "            return Node(root = True, \n",
    "                        label = y_train.value_counts().sort_values(ascending=False).index[0])\n",
    "        \n",
    "        # 3. calculate the largest inforamtion gain, use Ag to representative the best feature\n",
    "        max_feature_id, max_info_gain = self.get_info_gain(np.array(train_data))\n",
    "        max_feature_name = features[max_feature_id]\n",
    "        \n",
    "        # 4. if the information gain is smaller than threshold, set T as single node,\n",
    "        #    and use the most C as the label, return T \n",
    "        if max_info_gain < self.epsilon:\n",
    "            return Node(root = True, \n",
    "                       label = y_train.value_counts().sort_values(ascending=False).index[0])\n",
    "\n",
    "        # 5. splitting D according to every possible values in the feature A\n",
    "        # create new node \n",
    "        node_tree = Node(root = False, feature_name = max_feature_name, \n",
    "                         feature = max_feature_id)\n",
    "        print(node_tree.feature_name, node_tree.feature)\n",
    "        \n",
    "        feature_list = train_data[max_feature_name].value_counts().index\n",
    "        for f in feature_list:\n",
    "            # drop the largest information gain feature from train_data\n",
    "            # sub_train_df : A - Ag\n",
    "            sub_train_df = train_data[train_data[max_feature_name] == f].drop([\n",
    "                                                        max_feature_name], axis=1)\n",
    "            \n",
    "            print(max_feature_name, f)\n",
    "            # 6. create tree recursively\n",
    "            sub_tree = self.train(sub_train_df)\n",
    "            print('add_node', max_feature_name, f)\n",
    "            node_tree.add_node(f, sub_tree)\n",
    "        \n",
    "        #pprint.pprint(node_tree.tree)\n",
    "    \n",
    "        return node_tree \n",
    "    \n",
    "    def fit(self, train_data):\n",
    "        self._tree = self.train(train_data)\n",
    "        \n",
    "        return self._tree\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        return self._tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "own house 2\n",
      "own house no\n",
      "have job 1\n",
      "have job no\n",
      "add_node have job no\n",
      "have job yes\n",
      "add_node have job yes\n",
      "add_node own house no\n",
      "own house yes\n",
      "add_node own house yes\n"
     ]
    }
   ],
   "source": [
    "datasets, labels = create_data()\n",
    "data_df = pd.DataFrame(datasets, columns = labels)\n",
    "dt = DTree()\n",
    "tree = dt.fit(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tree': {'yes': {'tree': {}, 'label': 'yes', 'feature': None}, 'no': {'tree': {'yes': {'tree': {}, 'label': 'yes', 'feature': None}, 'no': {'tree': {}, 'label': 'no', 'feature': None}}, 'label': None, 'feature': 1}}, 'label': None, 'feature': 2}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.predict(['old', 'yes', 'no', 'intermediate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
