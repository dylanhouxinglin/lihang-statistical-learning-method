{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "逻辑回归(logistic regression)，一种典型的分类方法.\n",
    "\n",
    "Logistic distribution 的分布函数是一条 S 形曲线，即 sigmoid 函数 :\n",
    "\n",
    "$$g(x) = {1\\over 1+e^{-x}}$$\n",
    "\n",
    "对于二分类问题，可以看作是伯努利试验，即 :\n",
    "\n",
    "$$P(y=1|x) = p ; P(y=0|x) = 1-p$$\n",
    "\n",
    "$$P(x|\\theta)=\\theta^x(1-\\theta)^{1-x}$$\n",
    "\n",
    "对应的似然函数为 :\n",
    "\n",
    "$$L(x)=\\Pi P(y|x) = \\Pi x^y (1-x)^{1-y} = \\Pi g(x)^y (1-g(x))^{1-y}$$\n",
    "\n",
    "则对数似然函数为 :\n",
    "\n",
    "$$L(\\theta) = \\Pi \\log g(x)^y (1-g(x))^{1-y}$$\n",
    "\n",
    "$$=\\sum \\log g(x)^y + \\log (1-g(x))^{1-y}$$\n",
    "\n",
    "$$=\\sum y\\log g(x) + (1-y)\\log (1-g(x))$$\n",
    "\n",
    "$$=\\sum y\\log g(\\theta^Tx) + (1-y)\\log (1-g(\\theta^Tx))$$\n",
    "\n",
    "这时我们只需要最大化似然函数，就可以得到最优的参数估计，这里对其取负后除$n$作为最终的损失函数 :\n",
    "\n",
    "$$J(\\theta) = -{1\\over n}L(\\theta)=-{1\\over n}\\sum_{i=1}^n y\\log g(\\theta^Tx) + (1-y)\\log (1-g(\\theta^Tx))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    data = np.array(df)\n",
    "    \n",
    "    return data[:100, :-1], data[:100, -1]\n",
    "    \n",
    "    \n",
    "data, label = get_data()\n",
    "train_x, test_x, train_y, test_y = train_test_split(data, label, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, max_iter=200, learning_rate=0.01):\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def data_matrix(self, x):\n",
    "        data_mat = []\n",
    "        for d in x:\n",
    "            data_mat.append([1.0, *d])\n",
    "        \n",
    "        return np.array(data_mat)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        data_mat = self.data_matrix(x)\n",
    "        self.w = np.zeros((len(data_mat[0]), 1), dtype=np.float32)\n",
    "\n",
    "        for iter_ in range(self.max_iter):\n",
    "            result = self.sigmoid(np.dot(data_mat, self.w))\n",
    "            y = np.array(y).reshape(len(y), 1)\n",
    "            error = np.transpose(y - result)\n",
    "            self.w += self.learning_rate * np.transpose(np.dot(error, data_mat))\n",
    "            '''\n",
    "            for i in range(len(x)):\n",
    "                result = self.sigmoid(np.dot(data_mat[i], self.w))\n",
    "                error = y[i] - result\n",
    "                print(error)\n",
    "                print(np.transpose([data_mat[i]]).shape)\n",
    "                sys.exit()\n",
    "                self.w += self.learning_rate * error * np.transpose(\n",
    "                    [data_mat[i]])\n",
    "            '''\n",
    "            \n",
    "    def score(self, x_test, y_test):\n",
    "        right = 0\n",
    "        x_test = self.data_matrix(x_test)\n",
    "\n",
    "        for x, y in zip(x_test, y_test):\n",
    "            prediction = self.sigmoid(np.dot(x, self.w))\n",
    "            if (prediction >= 0.5 and y == 1) or (prediction < 0.5 and y == 0):\n",
    "                right += 1\n",
    "        \n",
    "        print(right / len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train_x, train_y)\n",
    "lr.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
